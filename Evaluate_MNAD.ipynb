{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNAD Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from data.CustomDataset import CustomImageDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR_SUFFIX = 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "  \"gpus\": \"1\",                            # gpus (set 1 or None)\n",
    "  \"batch_size\": 1,                        # batch size for testing\n",
    "  \"h\": 256,                               # height of input images\n",
    "  \"w\": 256,                               # width of input images\n",
    "  \"c\": 3,                                 # channel of input images\n",
    "  \"method\": \"recon\",                      # The target task for anoamly detection  (pred or recon)\n",
    "  \"t_length\": 1,                          # length of the frame sequences\n",
    "  \"fdim\": 512,                            # channel dimension of the features\n",
    "  \"mdim\": 512,                            # channel dimension of the memory items\n",
    "  \"msize\": 10,                            # number of the memory items\n",
    "  \"alpha\": 0.7,                           # weight for the anomality score\n",
    "  \"th\": 0.015,                            # threshold for test updating\n",
    "  \"num_workers\": 1,                       # number of workers for the test loader\n",
    "  \"dataset_type\": \"clean_road\",           # type of dataset: clean_road\n",
    "  \"dataset_path\": \"./dataset\",            # directory of data\n",
    "  \"label_path\": \"./dataset\",              # directory of labels\n",
    "  \"label_file\": \"metadata.csv\",           # name of the label file\n",
    "  \"model_path\": \"model/trained\",          # directory of model\n",
    "  \"model_file\": \"model.pth\",              # name of the model file\n",
    "  \"m_items_path\": \"model/trained\",        # directory of memory items\n",
    "  \"m_items_file\": \"keys.pt\"               # name of the memory items file\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "if args.gpus is not None and torch.cuda.is_available():\n",
    "  print(torch.cuda.is_available())\n",
    "\n",
    "  print(torch.cuda.device_count())\n",
    "\n",
    "  print(torch.cuda.current_device())\n",
    "\n",
    "  print(torch.cuda.device(0))\n",
    "\n",
    "  print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "if args.gpus is None:\n",
    "    gpus = \"0\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus\n",
    "else:\n",
    "    gpus = \"\"\n",
    "    for i in range(len(args.gpus)):\n",
    "        gpus = gpus + args.gpus[i] + \",\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus[:-1]\n",
    "\n",
    "#torch.backends.cudnn.enabled = True # make sure to use cudnn for computational performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = os.path.join(args.dataset_path, args.dataset_type, 'testing', DATASET_DIR_SUFFIX)\n",
    "test_label_file = os.path.join(args.label_path, args.dataset_type, args.label_file)\n",
    "\n",
    "#transform = T.Resize((args.h,args.w))\n",
    "transform = T.Compose([T.ToTensor(),])\n",
    "\n",
    "# Loading dataset\n",
    "test_dataset = CustomImageDataset(test_label_file, test_folder, transform = transform)\n",
    "test_size = len(test_dataset)\n",
    "\n",
    "test_batch = data.DataLoader(test_dataset, batch_size = args.batch_size,\n",
    "                              shuffle=True, num_workers=args.num_workers, drop_last=False)\n",
    "batch_size = len(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the trained model\n",
    "model_file = os.path.join(args.model_path, args.dataset_type, args.model_file)\n",
    "m_items_file = os.path.join(args.m_items_path, args.dataset_type, args.m_items_file)\n",
    "#model = torch.load(args.model_dir, map_location=torch.device('cpu'))\n",
    "model = torch.load(model_file)\n",
    "model.cuda()\n",
    "#m_items = torch.load(args.m_items_dir, map_location=torch.device('cpu'))\n",
    "m_items = torch.load(m_items_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
