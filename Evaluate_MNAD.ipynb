{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNAD Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "\n",
    "from data.CustomDataset import CustomImageDataset\n",
    "from evaluation_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR_SUFFIX = 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "  \"gpus\": \"1\",                            # gpus (set 1 or None)\n",
    "  \"batch_size\": 1,                        # batch size for testing\n",
    "  \"h\": 256,                               # height of input images\n",
    "  \"w\": 256,                               # width of input images\n",
    "  \"c\": 3,                                 # channel of input images\n",
    "  \"method\": \"recon\",                      # The target task for anoamly detection  (pred or recon)\n",
    "  \"t_length\": 1,                          # length of the frame sequences\n",
    "  \"fdim\": 512,                            # channel dimension of the features\n",
    "  \"mdim\": 512,                            # channel dimension of the memory items\n",
    "  \"msize\": 10,                            # number of the memory items\n",
    "  \"alpha\": 0.7,                           # weight for the anomality score\n",
    "  \"th\": 0.015,                            # threshold for test updating\n",
    "  \"num_workers\": 1,                       # number of workers for the test loader\n",
    "  \"dataset_type\": \"clean_road\",           # type of dataset: clean_road\n",
    "  \"dataset_path\": \"./dataset\",            # directory of data\n",
    "  \"label_path\": \"./dataset\",              # directory of labels\n",
    "  \"label_file\": \"metadata.csv\",           # name of the label file\n",
    "  \"model_path\": \"model/trained\",          # directory of model\n",
    "  \"model_file\": \"model.pth\",              # name of the model file\n",
    "  \"m_items_path\": \"model/trained\",        # directory of memory items\n",
    "  \"m_items_file\": \"keys.pt\"               # name of the memory items file\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x74a6e42aeec0>\n",
      "Quadro T2000 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "if args.gpus is not None and torch.cuda.is_available():\n",
    "  print(torch.cuda.is_available())\n",
    "\n",
    "  print(torch.cuda.device_count())\n",
    "\n",
    "  print(torch.cuda.current_device())\n",
    "\n",
    "  print(torch.cuda.device(0))\n",
    "\n",
    "  print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "if args.gpus is None:\n",
    "    gpus = \"0\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus\n",
    "else:\n",
    "    gpus = \"\"\n",
    "    for i in range(len(args.gpus)):\n",
    "        gpus = gpus + args.gpus[i] + \",\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus[:-1]\n",
    "\n",
    "#torch.backends.cudnn.enabled = True # make sure to use cudnn for computational performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = os.path.join(args.dataset_path, args.dataset_type, 'testing', DATASET_DIR_SUFFIX)\n",
    "test_label_file = os.path.join(args.label_path, args.dataset_type, args.label_file)\n",
    "\n",
    "#transform = T.Resize((args.h,args.w))\n",
    "transform = T.Compose([T.ToTensor(),])\n",
    "\n",
    "# Loading dataset\n",
    "test_dataset = CustomImageDataset(test_label_file, test_folder, transform = transform, use_cv2=True)\n",
    "test_size = len(test_dataset)\n",
    "\n",
    "test_batch = data.DataLoader(test_dataset, batch_size = args.batch_size,\n",
    "                              shuffle=True, num_workers=args.num_workers, drop_last=False)\n",
    "batch_size = len(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the trained model\n",
    "model_file = os.path.join(args.model_path, args.dataset_type, args.model_file)\n",
    "m_items_file = os.path.join(args.m_items_path, args.dataset_type, args.m_items_file)\n",
    "#model = torch.load(args.model_dir, map_location=torch.device('cpu'))\n",
    "model = torch.load(model_file)\n",
    "model.cuda()\n",
    "#m_items = torch.load(args.m_items_dir, map_location=torch.device('cpu'))\n",
    "m_items = torch.load(m_items_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_mse = nn.MSELoss(reduction='none')\n",
    "\n",
    "psnr_list = {}\n",
    "feature_distance_list = {}\n",
    "\n",
    "# Populate the dictionaries with the image names and empty lists\n",
    "for img_name in test_dataset.imgs_labels[\"filename\"].to_numpy():\n",
    "    psnr_list[img_name] = []\n",
    "    feature_distance_list[img_name] = []\n",
    "\n",
    "m_items_test = m_items.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of clean_road\n",
      "(129, 1)\n",
      "[[0.79564784]\n",
      " [0.47154563]\n",
      " [0.41300611]\n",
      " [0.40272919]\n",
      " [0.62047204]\n",
      " [0.782453  ]\n",
      " [0.49510114]\n",
      " [0.51275119]\n",
      " [0.71267989]\n",
      " [0.20168738]\n",
      " [0.51414479]\n",
      " [0.4106049 ]\n",
      " [0.66121247]\n",
      " [0.64233846]\n",
      " [0.5082961 ]\n",
      " [0.32736858]\n",
      " [0.68735506]\n",
      " [0.65859071]\n",
      " [0.55345455]\n",
      " [0.38701058]\n",
      " [0.75586877]\n",
      " [0.44219017]\n",
      " [0.40581202]\n",
      " [0.38978965]\n",
      " [0.64609395]\n",
      " [0.62352912]\n",
      " [0.56023779]\n",
      " [0.50647671]\n",
      " [0.44092348]\n",
      " [0.56959701]\n",
      " [0.25934105]\n",
      " [0.47910843]\n",
      " [0.47461326]\n",
      " [0.41798061]\n",
      " [0.61668036]\n",
      " [0.86177   ]\n",
      " [0.66951401]\n",
      " [0.43435714]\n",
      " [0.49907334]\n",
      " [0.32850573]\n",
      " [0.54373238]\n",
      " [0.56511702]\n",
      " [0.2883019 ]\n",
      " [0.50187352]\n",
      " [0.63411324]\n",
      " [0.80725245]\n",
      " [0.27641902]\n",
      " [0.73373171]\n",
      " [0.59937038]\n",
      " [0.37326901]\n",
      " [0.2546355 ]\n",
      " [0.58826723]\n",
      " [0.21599441]\n",
      " [0.68931818]\n",
      " [0.63229006]\n",
      " [0.5739847 ]\n",
      " [0.58092392]\n",
      " [0.58567944]\n",
      " [0.55630591]\n",
      " [0.67396715]\n",
      " [0.58806113]\n",
      " [0.36376716]\n",
      " [0.30218809]\n",
      " [0.65400275]\n",
      " [0.57723189]\n",
      " [0.54373238]\n",
      " [0.5217744 ]\n",
      " [0.55644882]\n",
      " [0.62884397]\n",
      " [0.5615813 ]\n",
      " [0.59118822]\n",
      " [0.55944323]\n",
      " [0.25110957]\n",
      " [0.34500119]\n",
      " [0.80587109]\n",
      " [0.57220097]\n",
      " [0.64395671]\n",
      " [0.59429567]\n",
      " [0.41125258]\n",
      " [0.36219519]\n",
      " [0.72483905]\n",
      " [0.54601251]\n",
      " [0.73779394]\n",
      " [0.51275119]\n",
      " [0.83349407]\n",
      " [0.60407598]\n",
      " [0.47014854]\n",
      " [0.46956036]\n",
      " [0.46285105]\n",
      " [0.62782889]\n",
      " [0.60222742]\n",
      " [0.56421278]\n",
      " [0.65308491]\n",
      " [0.29501683]\n",
      " [0.47200555]\n",
      " [0.44507372]\n",
      " [0.51805654]\n",
      " [0.26763816]\n",
      " [0.57097559]\n",
      " [0.6989758 ]\n",
      " [0.61232206]\n",
      " [0.63411324]\n",
      " [0.58217186]\n",
      " [0.88962067]\n",
      " [0.58395993]\n",
      " [0.54478732]\n",
      " [0.45652532]\n",
      " [0.88284131]\n",
      " [0.45753951]\n",
      " [0.7888087 ]\n",
      " [0.50797038]\n",
      " [0.58398016]\n",
      " [0.67212959]\n",
      " [0.39082212]\n",
      " [0.62248853]\n",
      " [0.52353059]\n",
      " [0.582838  ]\n",
      " [0.16040707]\n",
      " [0.62025078]\n",
      " [0.42134533]\n",
      " [0.90122446]\n",
      " [0.5825909 ]\n",
      " [0.31736364]\n",
      " [0.63411324]\n",
      " [0.36493879]\n",
      " [0.2787152 ]\n",
      " [0.79471945]\n",
      " [0.40163308]\n",
      " [0.57404126]]\n",
      "The result of  clean_road\n",
      "AUC:  81.7741935483871 %\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation of', args.dataset_type)\n",
    "model.eval()\n",
    "\n",
    "for j,(images, labels) in enumerate(test_batch):\n",
    "    imgs = images[\"file\"]\n",
    "    img_name = images[\"name\"][0]\n",
    "\n",
    "    if args.gpus is not None and torch.cuda.is_available():\n",
    "        imgs = imgs.cuda()\n",
    "\n",
    "    if args.method == 'pred':\n",
    "        outputs, feas, updated_feas, m_items_test, softmax_score_query, softmax_score_memory, _, _, _, compactness_loss = model.forward(imgs[:,0:3*4], m_items_test, False)\n",
    "        mse_imgs = torch.mean(loss_func_mse((outputs[0]+1)/2, (imgs[0,3*4:]+1)/2)).item()\n",
    "        mse_feas = compactness_loss.item()\n",
    "\n",
    "        # Calculating the threshold for updating at the test time\n",
    "        point_sc = point_score(outputs, imgs[:,3*4:])\n",
    "\n",
    "    else:\n",
    "        outputs, feas, updated_feas, m_items_test, softmax_score_query, softmax_score_memory, compactness_loss = model.forward(imgs, m_items_test, False)\n",
    "        mse_imgs = torch.mean(loss_func_mse((outputs[0]+1)/2, (imgs[0]+1)/2)).item()\n",
    "        mse_feas = compactness_loss.item()\n",
    "\n",
    "        # Calculating the threshold for updating at the test time\n",
    "        point_sc = point_score(outputs, imgs)\n",
    "\n",
    "    if  point_sc < args.th:\n",
    "        query = nn.functional.normalize(feas, dim=1)\n",
    "        query = query.permute(0,2,3,1) # b X h X w X d\n",
    "        m_items_test = model.memory.update(query, m_items_test, False)\n",
    "    \n",
    "    psnr_list[img_name].append(psnr(mse_imgs))\n",
    "    feature_distance_list[img_name].append(mse_feas)\n",
    "\n",
    "# TODO: Check this part\n",
    "# Measuring the abnormality score and the AUC\n",
    "anomaly_score_total_list = []\n",
    "# I removed the normalization of psnr_list and feature_distance_list done over whole video frames but maybe I need to normalize.\n",
    "# The normalization was performed by the functions anomaly_score_list and anomaly_score_list_inv.\n",
    "# Old code:\n",
    "#for video in sorted(videos_list):\n",
    "    #video_name = video.split('/')[-1]\n",
    "    #anomaly_score_total_list += score_sum(anomaly_score_list(psnr_list[video_name]), \n",
    "                                     #anomaly_score_list_inv(feature_distance_list[video_name]), args.alpha)\n",
    "# New code:\n",
    "#for img_name in test_dataset.imgs_labels[\"filename\"].to_numpy():\n",
    "    #anomaly_score_total_list += score_sum(psnr_list[img_name], feature_distance_list[img_name], args.alpha)\n",
    "\n",
    "# New code with single list and normalization TODO: Test result\n",
    "psnr_listed = anomaly_score_list(list(psnr_list.values()))\n",
    "feature_distance_listed = anomaly_score_list_inv(list(feature_distance_list.values()))\n",
    "anomaly_score_total_list = score_sum(psnr_listed, feature_distance_listed, args.alpha)\n",
    "\n",
    "anomaly_score_total_list = np.asarray(anomaly_score_total_list)\n",
    "\n",
    "print(anomaly_score_total_list.shape)\n",
    "print(anomaly_score_total_list)\n",
    "\n",
    "# TODO: Check the correct values for labels and scores\n",
    "anomaly_score_total_list = np.expand_dims(anomaly_score_total_list, axis=0)\n",
    "labels_list = np.expand_dims(1 - test_dataset.imgs_labels[\"label\"].to_numpy(), axis=0)\n",
    "accuracy = AUC(anomaly_score_total_list, labels_list)\n",
    "\n",
    "print('The result of ', args.dataset_type)\n",
    "print('AUC: ', accuracy*100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
