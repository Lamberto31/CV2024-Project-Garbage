{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNAD Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "from data.CustomDataset import CustomImageDataset\n",
    "from data.CustomDataset import augment_dataset\n",
    "from data.CustomDataset import show_augmented_dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR_SUFFIX = 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "  \"gpus\": \"1\",                                                  # gpus (set 1 or None)\n",
    "  \"train_batch_size\": 4,                                        # batch size for training\n",
    "  \"val_batch_size\": 1,                                          # batch size for validation\n",
    "  \"epochs\": 60,                                                 # number of epochs for training\n",
    "  \"loss_compact\": 0.1,                                          # weight of the feature compactness loss\n",
    "  \"loss_separate\": 0.1,                                         # weight of the feature separateness loss\n",
    "  \"h\": 256,                                                     # height of input images\n",
    "  \"w\": 256,                                                     # width of input images\n",
    "  \"c\": 3,                                                       # channel of input images\n",
    "  \"lr\": 2e-4,                                                   # initial learning rate\n",
    "  \"method\": \"recon\",                                            # The target task for anoamly detection (pred or recon)\n",
    "  \"t_length\": 1,                                                # length of the frame sequences\n",
    "  \"fdim\": 512,                                                  # channel dimension of the features\n",
    "  \"mdim\": 512,                                                  # channel dimension of the memory items\n",
    "  \"msize\": 10,                                                  # number of the memory items\n",
    "  \"train_num_workers\": 2,                                       # number of workers for the train loader\n",
    "  \"val_num_workers\": 1,                                         # number of workers for the validation loader\n",
    "  \"dataset_type\": \"clean_road\",                                 # type of dataset: clean_road\n",
    "  \"dataset_path\": \"./dataset\",                                  # directory of data\n",
    "  \"label_path\": \"./dataset\",                                    # directory of labels\n",
    "  \"label_file\": \"metadata.csv\",                                 # name of the label file\n",
    "  \"exp_dir\": \"./log\",                                           # directory of log\n",
    "  \"split_dataset\": True,                                        # whether to split the dataset\n",
    "  \"val_label_file\": \"validation_labels.csv\",                    # name of the validation label file (used if split_dataset is False)\n",
    "  \"validate_non_anomalous\": True,                               # whether to also validate on just non-anomalous data\n",
    "  \"na_val_label_file\": \"non_anom_validation_labels.csv\"         # name of the non-anomalous validation label file (used if split_dataset is False and validate_non_anomalous is True)\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "if args.gpus is not None and torch.cuda.is_available():\n",
    "\n",
    "  print(torch.cuda.device_count())\n",
    "\n",
    "  print(torch.cuda.current_device())\n",
    "\n",
    "  print(torch.cuda.device(0))\n",
    "\n",
    "  print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "if args.gpus is None:\n",
    "    gpus = \"0\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus\n",
    "else:\n",
    "    gpus = \"\"\n",
    "    for i in range(len(args.gpus)):\n",
    "        gpus = gpus + args.gpus[i] + \",\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus[:-1]\n",
    "\n",
    "#torch.backends.cudnn.enabled = True # make sure to use cudnn for computational performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(args.dataset_path, args.dataset_type, DATASET_DIR_SUFFIX)\n",
    "data_label_file = os.path.join(args.label_path, args.dataset_type, args.label_file)\n",
    "\n",
    "#transform = T.Resize((args.h,args.w))\n",
    "transform = T.Compose([T.ToTensor(),])\n",
    "\n",
    "# Create dataset\n",
    "dataset = CustomImageDataset(data_label_file, data_folder, transform = transform, use_cv2=True)\n",
    "dataset_size = len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.split_dataset:\n",
    "    if args.validate_non_anomalous:\n",
    "        train_dataset, validation_dataset, na_validation_dataset, _ = dataset.split_train_validation_test(non_anomalous_validation=True)\n",
    "    train_dataset, validation_dataset, _ = dataset.split_train_validation_test()\n",
    "else:\n",
    "    train_dataset = dataset\n",
    "    validation_label_file = os.path.join(args.label_path, args.dataset_type, args.val_label_file)\n",
    "    validation_dataset = CustomImageDataset(validation_label_file, data_folder, transform = transform, use_cv2=True)\n",
    "    if args.validate_non_anomalous:\n",
    "        na_validation_label_file = os.path.join(args.label_path, args.dataset_type, args.na_val_label_file)\n",
    "        na_validation_dataset = CustomImageDataset(na_validation_label_file, data_folder, transform = transform, use_cv2=True)\n",
    "train_size = len(train_dataset)\n",
    "validation_size = len(validation_dataset)\n",
    "if args.validate_non_anomalous:\n",
    "    non_anomalous_validation_size = len(na_validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmentation transform list\n",
    "augmentation_transform_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AutoAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enabled = False\n",
    "if enabled:\n",
    "    augmentation_transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.AutoAugment(),\n",
    "        T.ToTensor(),    \n",
    "    ])\n",
    "    transform_name = \"AutoAugment\"\n",
    "    applications_number = 3\n",
    "    transform_dict = {\"name\": transform_name, \"transform\": augmentation_transform, \"applications_number\": applications_number}\n",
    "    augmentation_transform_list.append(transform_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enabled = False\n",
    "if enabled:\n",
    "    augmentation_transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.RandAugment(),\n",
    "        T.ToTensor(),    \n",
    "    ])\n",
    "    transform_name = \"RandAugment\"\n",
    "    applications_number = 3\n",
    "    transform_dict = {\"name\": transform_name, \"transform\": augmentation_transform, \"applications_number\": applications_number}\n",
    "    augmentation_transform_list.append(transform_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AugMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enabled = False\n",
    "if enabled:\n",
    "    augmentation_transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.AugMix(),\n",
    "        T.ToTensor(),    \n",
    "    ])\n",
    "    transform_name = \"AugMix\"\n",
    "    applications_number = 3\n",
    "    transform_dict = {\"name\": transform_name, \"transform\": augmentation_transform, \"applications_number\": applications_number}\n",
    "    augmentation_transform_list.append(transform_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TrivialAgumentWide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enabled = False\n",
    "if enabled:\n",
    "    augmentation_transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.TrivialAugmentWide(),\n",
    "        T.ToTensor(),    \n",
    "    ])\n",
    "    transform_name = \"TrivialAugmentWide\"\n",
    "    applications_number = 3\n",
    "    transform_dict = {\"name\": transform_name, \"transform\": augmentation_transform, \"applications_number\": applications_number}\n",
    "    augmentation_transform_list.append(transform_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augment_dataset function to create augmented dataset\n",
    "augmented_train_dataset = augment_dataset(train_dataset, augmentation_transform_list, create_dict=False)\n",
    "augmented_train_size = len(augmented_train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "# Training\n",
    "train_batch = data.DataLoader(augmented_train_dataset, batch_size = args.train_batch_size,\n",
    "                              shuffle=True, num_workers=args.train_num_workers, drop_last=True)\n",
    "train_batch_size = len(train_batch)\n",
    "# Validation\n",
    "validation_batch = data.DataLoader(validation_dataset, batch_size = args.val_batch_size,\n",
    "                                   shuffle=True, num_workers=args.val_num_workers, drop_last=False)\n",
    "# Non-anomalous validation\n",
    "if args.validate_non_anomalous:\n",
    "    na_validation_batch = data.DataLoader(na_validation_dataset, batch_size = args.val_batch_size,\n",
    "                                   shuffle=True, num_workers=args.val_num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_augmented_dataset_info(augmented_train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setting\n",
    "assert args.method == 'pred' or args.method == 'recon', 'Wrong task name'\n",
    "if args.method == 'pred':\n",
    "    from model.final_future_prediction_with_memory_spatial_sumonly_weight_ranking_top1 import *\n",
    "    model = convAE(args.c, args.t_length, args.msize, args.fdim, args.mdim)\n",
    "else:\n",
    "    from model.Reconstruction import *\n",
    "    model = convAE(args.c, memory_size = args.msize, feature_dim = args.fdim, key_dim = args.mdim)\n",
    "params_encoder =  list(model.encoder.parameters())\n",
    "params_decoder = list(model.decoder.parameters())\n",
    "params = params_encoder + params_decoder\n",
    "optimizer = torch.optim.Adam(params, lr = args.lr)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max =args.epochs)\n",
    "\n",
    "if args.gpus is not None and torch.cuda.is_available():\n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and create (if necessary) the log directory\n",
    "log_dir = os.path.join(args.exp_dir, args.dataset_type, args.method)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Write the augmentation list to a json file\n",
    "augmentations_file = open(os.path.join(log_dir, \"augmentations.json\"), \"w\")\n",
    "# Remove the transform objects from the dictionary\n",
    "for transform_dict in augmentation_transform_list:\n",
    "    transform_dict.pop(\"transform\")\n",
    "# Write the json file\n",
    "json.dump(augmentation_transform_list, augmentations_file)\n",
    "augmentations_file.close()\n",
    "\n",
    "# Set the tensorboard writer\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "os.path.join(log_dir, 'tensorboard_training_{}'.format(timestamp))\n",
    "writer = SummaryWriter(os.path.join(log_dir, 'training_{}'.format(timestamp)))\n",
    "# Set the log file\n",
    "orig_stdout = sys.stdout\n",
    "f = open(os.path.join(log_dir, 'log.txt'),'w')\n",
    "sys.stdout= f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_func_mse = nn.MSELoss(reduction='none')\n",
    "# Initialize the memory items\n",
    "m_items = F.normalize(torch.rand((args.msize, args.mdim), dtype=torch.float), dim=1)\n",
    "if args.gpus is not None and torch.cuda.is_available():\n",
    "  m_items = m_items.cuda()\n",
    "\n",
    "# Create pandas dataframe to store the results\n",
    "#results = pd.DataFrame(columns=['epoch', 'phase', 'loss', 'loss_pixel', 'loss_compactness', 'loss_separateness'])\n",
    "rows = []\n",
    "\n",
    "# Training\n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "\n",
    "    train_loss_acc = 0\n",
    "    train_loss_pixel_acc = 0\n",
    "    train_separateness_loss_acc = 0\n",
    "    train_loss_compactness_acc = 0\n",
    "    for j,(images, labels) in enumerate(train_batch):\n",
    "\n",
    "        if args.gpus is not None and torch.cuda.is_available():\n",
    "          imgs = images[\"file\"].cuda()\n",
    "\n",
    "        if args.method == 'pred':\n",
    "            outputs, _, _, m_items, softmax_score_query, softmax_score_memory, train_separateness_loss, train_compactness_loss = model.forward(imgs[:,0:12], m_items, True)\n",
    "        else:\n",
    "            outputs, _, _, m_items, softmax_score_query, softmax_score_memory, train_separateness_loss, train_compactness_loss = model.forward(imgs, m_items, True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if args.method == 'pred':\n",
    "            train_loss_pixel = torch.mean(loss_func_mse(outputs, imgs[:,12:]))\n",
    "        else:\n",
    "            train_loss_pixel = torch.mean(loss_func_mse(outputs, imgs))\n",
    "\n",
    "        train_loss = train_loss_pixel + args.loss_compact * train_compactness_loss + args.loss_separate * train_separateness_loss\n",
    "        train_loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Accumulate the losses\n",
    "        train_loss_acc += train_loss.item()\n",
    "        train_loss_pixel_acc += train_loss_pixel.item()\n",
    "        train_separateness_loss_acc += train_separateness_loss.item()\n",
    "        train_loss_compactness_acc += train_compactness_loss.item()\n",
    "    \n",
    "    # Calculate the average losses\n",
    "    train_loss = train_loss_acc / len(train_batch)\n",
    "    train_loss_pixel = train_loss_pixel_acc / len(train_batch)\n",
    "    train_separateness_loss = train_separateness_loss_acc / len(train_batch)\n",
    "    train_compactness_loss = train_loss_compactness_acc / len(train_batch)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "\n",
    "    val_loss_acc = 0\n",
    "    val_loss_pixel_acc = 0\n",
    "    val_separateness_loss_acc = 0\n",
    "    for j, (images, labels) in enumerate(validation_batch):\n",
    "        \n",
    "        if args.gpus is not None and torch.cuda.is_available():\n",
    "            imgs = images[\"file\"].cuda()\n",
    "        \n",
    "        if args.method == 'pred':\n",
    "            outputs, _, _, _, _, _, val_separateness_loss = model.forward(imgs[:,0:12], m_items, False)\n",
    "        else:\n",
    "            outputs, _, _, _, _, _, val_separateness_loss = model.forward(imgs, m_items, False)\n",
    "        \n",
    "        if args.method == 'pred':\n",
    "            val_loss_pixel = torch.mean(loss_func_mse(outputs, imgs[:,12:]))\n",
    "        else:\n",
    "            val_loss_pixel = torch.mean(loss_func_mse(outputs, imgs))\n",
    "\n",
    "        val_loss = val_loss_pixel + args.loss_compact * train_compactness_loss + args.loss_separate * val_separateness_loss\n",
    "\n",
    "        # Accumulate the losses\n",
    "        val_loss_acc += val_loss.item()\n",
    "        val_loss_pixel_acc += val_loss_pixel.item()\n",
    "        val_separateness_loss_acc += val_separateness_loss.item()\n",
    "    \n",
    "    # Calculate the average losses\n",
    "    val_loss = val_loss_acc / len(validation_batch)\n",
    "    val_loss_pixel = val_loss_pixel_acc / len(validation_batch)\n",
    "    val_separateness_loss = val_separateness_loss_acc / len(validation_batch)\n",
    "    \n",
    "    # Validation on non-anomalous data\n",
    "    if args.validate_non_anomalous:\n",
    "        na_val_loss_acc = 0\n",
    "        na_val_loss_pixel_acc = 0\n",
    "        na_val_separateness_loss_acc = 0\n",
    "        for j, (images, labels) in enumerate(na_validation_batch):\n",
    "        \n",
    "            if args.gpus is not None and torch.cuda.is_available():\n",
    "                imgs = images[\"file\"].cuda()\n",
    "            \n",
    "            if args.method == 'pred':\n",
    "                outputs, _, _, _, _, _, na_val_separateness_loss = model.forward(imgs[:,0:12], m_items, False)\n",
    "            else:\n",
    "                outputs, _, _, _, _, _, na_val_separateness_loss = model.forward(imgs, m_items, False)\n",
    "            \n",
    "            if args.method == 'pred':\n",
    "                na_val_loss_pixel = torch.mean(loss_func_mse(outputs, imgs[:,12:]))\n",
    "            else:\n",
    "                na_val_loss_pixel = torch.mean(loss_func_mse(outputs, imgs))\n",
    "\n",
    "            na_val_loss = na_val_loss_pixel + args.loss_compact * train_compactness_loss + args.loss_separate * na_val_separateness_loss\n",
    "\n",
    "            # Accumulate the losses\n",
    "            na_val_loss_acc += na_val_loss.item()\n",
    "            na_val_loss_pixel_acc += na_val_loss_pixel.item()\n",
    "            na_val_separateness_loss_acc += na_val_separateness_loss.item()\n",
    "        \n",
    "        # Calculate the average losses\n",
    "        na_val_loss = na_val_loss_acc / len(na_validation_batch)\n",
    "        na_val_loss_pixel = na_val_loss_pixel_acc / len(na_validation_batch)\n",
    "        na_val_separateness_loss = na_val_separateness_loss_acc / len(na_validation_batch)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Store the results\n",
    "    rows.append({'epoch': epoch + 1, 'phase': 'train', 'loss': train_loss, 'loss_pixel': train_loss_pixel, 'loss_compactness': train_compactness_loss, 'loss_separateness': train_separateness_loss})\n",
    "    rows.append({'epoch': epoch + 1, 'phase': 'validation', 'loss': val_loss, 'loss_pixel': val_loss_pixel, 'loss_compactness': train_compactness_loss, 'loss_separateness': val_separateness_loss})\n",
    "    if args.validate_non_anomalous:\n",
    "        rows.append({'epoch': epoch + 1, 'phase': 'non_anomalous_validation', 'loss': na_val_loss, 'loss_pixel': na_val_loss_pixel, 'loss_compactness': train_compactness_loss, 'loss_separateness': na_val_separateness_loss})\n",
    "    \n",
    "    # Tensorboard\n",
    "    # Average loss for each dataset\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch + 1)\n",
    "    writer.add_scalar('Loss/validation', val_loss, epoch + 1)\n",
    "    if args.validate_non_anomalous:\n",
    "        writer.add_scalar('Loss/non_anomalous_validation', na_val_loss, epoch + 1)\n",
    "    # Average pixel loss for each dataset\n",
    "    writer.add_scalar('Loss_pixel/train', train_loss_pixel, epoch + 1)\n",
    "    writer.add_scalar('Loss_pixel/validation', val_loss_pixel, epoch + 1)\n",
    "    if args.validate_non_anomalous:\n",
    "        writer.add_scalar('Loss_pixel/non_anomalous_validation', na_val_loss_pixel, epoch + 1)\n",
    "    # Average compactness loss for each dataset\n",
    "    writer.add_scalar('Loss_compactness/train', train_compactness_loss, epoch + 1)\n",
    "    writer.add_scalar('Loss_compactness/validation', train_compactness_loss, epoch + 1)\n",
    "    if args.validate_non_anomalous:\n",
    "        writer.add_scalar('Loss_compactness/non_anomalous_validation', train_compactness_loss, epoch + 1)\n",
    "    # Average separateness loss for each dataset\n",
    "    writer.add_scalar('Loss_separateness/train', train_separateness_loss, epoch + 1)\n",
    "    writer.add_scalar('Loss_separateness/validation', val_separateness_loss, epoch + 1)\n",
    "    if args.validate_non_anomalous:\n",
    "        writer.add_scalar('Loss_separateness/non_anomalous_validation', na_val_separateness_loss, epoch + 1)\n",
    "    # Comparison of training and validation loss\n",
    "    loss_dict = {'Training': train_loss, 'Validation': val_loss}\n",
    "    if args.validate_non_anomalous:\n",
    "        loss_dict['Non-anomalous Validation'] = na_val_loss\n",
    "    writer.add_scalars('Training vs. Validation Loss', loss_dict, epoch + 1)\n",
    "\n",
    "    print('----------------------------------------')\n",
    "    print('Epoch:', epoch+1)\n",
    "    # Training results\n",
    "    if args.method == 'pred':\n",
    "        print('Train Loss: Prediction {:.6f}/ Compactness {:.6f}/ Separateness {:.6f}/ Total {:.6f}'.format(train_loss_pixel, train_compactness_loss, train_separateness_loss, train_loss))\n",
    "    else:\n",
    "        print('Train Loss: Reconstruction {:.6f}/ Compactness {:.6f}/ Separateness {:.6f}/ Total {:.6f}'.format(train_loss_pixel, train_compactness_loss, train_separateness_loss, train_loss))\n",
    "    # Validation results\n",
    "    if args.method == 'pred':\n",
    "        print('Validation Loss: Prediction {:.6f}/ Compactness {:.6f}/ Separateness {:.6f}/ Total {:.6f}'.format(val_loss_pixel, train_compactness_loss, val_separateness_loss, val_loss))\n",
    "    else:\n",
    "        print('Validation Loss: Reconstruction {:.6f}/ Compactness {:.6f}/ Separateness {:.6f}/ Total {:.6f}'.format(val_loss_pixel, train_compactness_loss, val_separateness_loss, val_loss))\n",
    "    # Non-anomalous validation results\n",
    "    if args.validate_non_anomalous:\n",
    "        if args.method == 'pred':\n",
    "            print('Non-anomalous Validation Loss: Prediction {:.6f}/ Compactness {:.6f}/ Separateness {:.6f}/ Total {:.6f}'.format(na_val_loss_pixel, train_compactness_loss, na_val_separateness_loss, na_val_loss))\n",
    "        else:\n",
    "            print('Non-anomalous Validation Loss: Reconstruction {:.6f}/ Compactness {:.6f}/ Separateness {:.6f}/ Total {:.6f}'.format(na_val_loss_pixel, train_compactness_loss, na_val_separateness_loss, na_val_loss))\n",
    "    print('Memory_items:')\n",
    "    print(m_items)\n",
    "    print('----------------------------------------')\n",
    "\n",
    "print('Training is finished')\n",
    "\n",
    "# Save the model and the memory items\n",
    "torch.save(model, os.path.join(log_dir, 'model.pth'))\n",
    "torch.save(m_items, os.path.join(log_dir, 'keys.pt'))\n",
    "\n",
    "# Save the results\n",
    "results = pd.DataFrame(rows)\n",
    "results.to_csv(os.path.join(log_dir, 'results.csv'))\n",
    "\n",
    "# Tensorboard\n",
    "writer.flush()\n",
    "\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a single mini-batch of images\n",
    "dataiter = iter(validation_batch)\n",
    "images, labels = next(dataiter)\n",
    "imgs = images[\"file\"].cuda()\n",
    "# Create random m_items for the graph\n",
    "m_items = F.normalize(torch.rand((args.msize, args.mdim), dtype=torch.float), dim=1).cuda()\n",
    "# Call the add_graph function\n",
    "writer.add_graph(model, (imgs, m_items))\n",
    "# Flush and close the writer\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
